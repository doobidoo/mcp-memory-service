{
  "id": "snapshot_1769302110764_4il0n3fke",
  "approvalId": "approval_1769302110761_x8nww4aqn",
  "approvalTitle": "Hybrid Search Tasks Document",
  "version": 1,
  "timestamp": "2026-01-25T00:48:30.764Z",
  "trigger": "initial",
  "status": "pending",
  "content": "# Tasks Document: Hybrid Search\n\n## Phase 1: Configuration\n\n- [ ] 1. Add HybridSearchSettings to config.py\n  - File: src/mcp_memory_service/config.py (modify existing)\n  - Add `HybridSearchSettings` class following existing pydantic-settings patterns\n  - Add to main `Settings` class as nested field\n  - Add backward-compat exports: `HYBRID_ALPHA`, `RECENCY_DECAY`\n  - Purpose: Enable configuration of hybrid search parameters via environment\n  - _Leverage: Existing settings patterns in config.py (HTTPSettings, StorageSettings)_\n  - _Requirements: R3, R5, R6_\n\n## Phase 2: Core Utilities\n\n- [ ] 2. Create hybrid search utility module\n  - File: src/mcp_memory_service/utils/hybrid_search.py (new)\n  - Implement `STOP_WORDS` frozenset (English common words)\n  - Implement `extract_query_keywords(query, existing_tags)` function\n  - Purpose: Extract potential tag matches from search queries\n  - _Requirements: R2_\n\n- [ ] 3. Implement RRF scoring functions\n  - File: src/mcp_memory_service/utils/hybrid_search.py (continue)\n  - Implement `rrf_score(rank, k=60)` pure function\n  - Implement `combine_results_rrf(vector_results, tag_matches, alpha, k)`\n  - Return combined scores with debug info dict\n  - Purpose: Fuse vector and tag search results fairly\n  - _Requirements: R1, R3_\n\n- [ ] 4. Implement adaptive alpha calculation\n  - File: src/mcp_memory_service/utils/hybrid_search.py (continue)\n  - Implement `get_adaptive_alpha(corpus_size, matching_tag_count, config)`\n  - Apply corpus size thresholds: <500 → 0.5, 500-5000 → 0.7, >5000 → 0.8\n  - Apply tag match boost: >=3 matches → 1.5x tag weight\n  - Purpose: Auto-tune hybrid balance based on data characteristics\n  - _Requirements: R5_\n\n- [ ] 5. Implement recency decay function\n  - File: src/mcp_memory_service/utils/hybrid_search.py (continue)\n  - Implement `apply_recency_decay(results, decay_rate)`\n  - Formula: `score * exp(-decay * days_since_update)`\n  - Handle decay=0 case (disabled)\n  - Purpose: Boost fresher memories in search results\n  - _Requirements: R6_\n\n## Phase 3: Unit Tests\n\n- [ ] 6. Write unit tests for keyword extraction\n  - File: tests/unit/test_hybrid_search.py (new)\n  - Test basic tokenization\n  - Test stop word removal\n  - Test punctuation handling\n  - Test tag validation with existing_tags\n  - Purpose: Verify keyword extraction works correctly\n  - _Requirements: R2_\n\n- [ ] 7. Write unit tests for RRF functions\n  - File: tests/unit/test_hybrid_search.py (continue)\n  - Test `rrf_score` basic formula\n  - Test `combine_results_rrf` with alpha=0, 0.5, 1.0\n  - Test overlap handling (same memory in both lists)\n  - Test empty input handling\n  - Purpose: Verify RRF combination is mathematically correct\n  - _Requirements: R1, R3_\n\n- [ ] 8. Write unit tests for adaptive alpha\n  - File: tests/unit/test_hybrid_search.py (continue)\n  - Test corpus size thresholds\n  - Test tag match boost\n  - Test explicit alpha override\n  - Purpose: Verify adaptive logic matches requirements\n  - _Requirements: R5_\n\n- [ ] 9. Write unit tests for recency decay\n  - File: tests/unit/test_hybrid_search.py (continue)\n  - Test decay formula (70 days → ~0.5x)\n  - Test decay=0 disabled case\n  - Test very old memories\n  - Purpose: Verify recency weighting is correct\n  - _Requirements: R6_\n\n## Phase 4: Service Layer Integration\n\n- [ ] 10. Modify MemoryService.retrieve_memories() for hybrid search\n  - File: src/mcp_memory_service/services/memory_service.py (modify)\n  - Import hybrid search utilities\n  - Add alpha determination logic (explicit > env > adaptive)\n  - Add parallel fetch: vector results + tag boost candidates\n  - Add RRF combination call\n  - Add recency decay application\n  - Preserve existing pagination and response format\n  - Purpose: Enable hybrid search in the main retrieval path\n  - _Leverage: Existing retrieve_memories() implementation_\n  - _Requirements: R1, R2, R3, R4, R5, R6_\n\n- [ ] 11. Add tag caching for performance\n  - File: src/mcp_memory_service/services/memory_service.py (continue)\n  - Cache `get_all_tags()` result for 60 seconds\n  - Use simple TTL cache (functools or manual)\n  - Purpose: Avoid repeated tag fetches on every query\n  - _Requirements: NFR Performance_\n\n## Phase 5: Integration Tests\n\n- [ ] 12. Write integration tests for hybrid retrieval\n  - File: tests/integration/test_hybrid_retrieve.py (new)\n  - Test hybrid enabled by default\n  - Test opt-out with HYBRID_ALPHA=1.0\n  - Test tag extraction boosts relevant results\n  - Test backward compatibility (API unchanged)\n  - Test pagination with hybrid results\n  - Purpose: Verify end-to-end hybrid search behavior\n  - _Leverage: Existing integration test patterns_\n  - _Requirements: R1, R4_\n\n## Phase 6: Evaluation Harness\n\n- [ ] 13. Create evaluation infrastructure\n  - File: tests/eval/__init__.py, tests/eval/conftest.py (new)\n  - Set up pytest fixtures for eval tests\n  - Create ground truth loader\n  - Add ranx dependency to pyproject.toml [dev]\n  - Purpose: Foundation for retrieval quality measurement\n  - _Requirements: R7_\n\n- [ ] 14. Create ground truth test set\n  - File: tests/eval/ground_truth.json (new)\n  - Minimum 50 query → expected_hash pairs\n  - Include known failure cases (e.g., \"rathole\" query)\n  - Include tag-sensitive test cases\n  - Categorize by query type\n  - Purpose: Establish objective evaluation baseline\n  - _Requirements: R7_\n\n- [ ] 15. Implement Hit Rate@10 evaluation\n  - File: tests/eval/test_hit_rate.py (new)\n  - Calculate % queries where correct memory in top 10\n  - Compare against ground truth\n  - Report per-category breakdown\n  - Purpose: Primary retrieval quality metric\n  - _Requirements: R7_\n\n- [ ] 16. Implement MRR evaluation\n  - File: tests/eval/test_mrr.py (new)\n  - Calculate Mean Reciprocal Rank\n  - Use ranx library for calculation\n  - Purpose: Measure ranking quality\n  - _Requirements: R7_\n\n- [ ] 17. Implement NDCG@10 evaluation\n  - File: tests/eval/test_ndcg.py (new)\n  - Calculate Normalized Discounted Cumulative Gain\n  - Use ranx library for calculation\n  - Purpose: Measure graded relevance quality\n  - _Requirements: R7_\n\n- [ ] 18. Create alpha sweep script\n  - File: tests/eval/sweep_alpha.py (new)\n  - Test alpha values [0.3, 0.5, 0.6, 0.7, 0.8, 1.0]\n  - Report Hit@10, MRR, NDCG@10 for each\n  - Output markdown table for comparison\n  - Purpose: Data-driven alpha selection\n  - _Requirements: R7_\n\n## Phase 7: Documentation & Cleanup\n\n- [ ] 19. Update tool descriptions\n  - File: src/mcp_memory_service/mcp_server.py (modify)\n  - Update `retrieve_memory` docstring to mention hybrid search\n  - Note opt-out mechanism in description\n  - Purpose: Inform users about new capability\n  - _Requirements: NFR Usability_\n\n- [ ] 20. Final review and cleanup\n  - Verify all tests pass\n  - Run ruff and basedpyright\n  - Check code line count targets (<200 feature, <150 eval)\n  - Purpose: Quality gate before merge\n  - _Requirements: NFR Code Architecture_\n\n## Dependency Graph\n\n```\n1 (config)\n├── 2 (keywords) ── 6 (test)\n├── 3 (rrf) ────── 7 (test)\n├── 4 (alpha) ──── 8 (test)\n└── 5 (recency) ── 9 (test)\n        │\n        ▼\n    10 (service) ── 11 (cache)\n        │\n        ▼\n    12 (integration tests)\n        │\n        ▼\n    13-18 (eval harness)\n        │\n        ▼\n    19-20 (docs & cleanup)\n```\n\n## Success Criteria\n\n| Metric | Target |\n|--------|--------|\n| All unit tests pass | Required |\n| All integration tests pass | Required |\n| Hit Rate@10 improvement | >60% → >85% |\n| Search latency p95 | <120ms |\n| New feature code | <200 lines |\n| Eval harness code | <150 lines |\n| Breaking API changes | 0 |\n",
  "fileStats": {
    "size": 7619,
    "lines": 215,
    "lastModified": "2026-01-25T00:48:19.517Z"
  },
  "comments": []
}
